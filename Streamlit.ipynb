{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Streamlit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAAAB/covid19/blob/main/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t20epxo3bATF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN4-fTxxDFGm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce8ce2c8-c78f-40e4-c3bb-76f66be4421d"
      },
      "source": [
        "!pip install pyngrok==4.1.1\r\n",
        "!pip install streamlit\r\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/a9/de2e15c92eb3aa4a2646ce3a7542317eb69ac47f667578ce8bf916320847/pyngrok-4.1.1.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-cp36-none-any.whl size=15971 sha256=c7ea2abcbb05118fca1938079a3226c0d753e02ac41a9a2d74c7c487e2e0ce85\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/71/0d/1695f7c8815c0beb3b5d9b35d6eec9243c87e6070fbe3977fa\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n",
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/59/ac66b8613d3652d6a0ade25055c448698e7c65baa82e69094f99721b138e/streamlit-0.75.0-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 10.1MB/s \n",
            "\u001b[?25hCollecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 61.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.8.1)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/d9/3d1f46b428fd7b646725896b58d2eddb84f79fd76912773e6193cf74263d/watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (3.12.4)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/9d/8fbf1f56cc5891e6c3295bf94fc176e9ab0a3ffdd090cc8b354ac2640f9a/pydeck-0.5.0-py2.py3-none-any.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.1.2)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/cb/ec98155c501b68dcb11314c7992cd3df6dce193fd763084338a117967d53/GitPython-3.1.12-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from streamlit) (20.8)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.0.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.2.0)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.23.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow; python_version < \"3.9\"->streamlit) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (51.3.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (4.3.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/cc/e8908bbb2921732f6851ebbbe4b77b925aab62e644ab9402f21c84fa6107/ipykernel-5.4.3-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.8)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.7.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (20.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=429ae5b6f63a5bb44af2e43d1685fdaa62892901806680958ced150ec5a27499\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.4.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: blinker, watchdog, ipykernel, pydeck, validators, smmap, gitdb, gitpython, base58, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.5 gitpython-3.1.12 ipykernel-5.4.3 pydeck-0.5.0 smmap-3.0.5 streamlit-0.75.0 validators-0.18.2 watchdog-1.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajad4oYZZ3g6",
        "outputId": "a961d74d-52ef-4a14-d80f-cc020918c4a0"
      },
      "source": [
        "%%writefile covid.py\r\n",
        "\r\n",
        "import pandas as pd, numpy as np\r\n",
        "import plotly.graph_objects as go\r\n",
        "import plotly.express as px\r\n",
        "from datetime import datetime, timedelta\r\n",
        "import streamlit as st\r\n",
        "\r\n",
        "PAGE_CONFIG = {\"page_title\":\"Covid-19 dashboard\",\"page_icon\":\":mask:\",\"layout\":\"wide\"}\r\n",
        "st.set_page_config(**PAGE_CONFIG)\r\n",
        "hide_streamlit_style = \"\"\"\r\n",
        "            <style>\r\n",
        "            #MainMenu {visibility: hidden;}\r\n",
        "            footer {visibility: hidden;}\r\n",
        "            </style>\r\n",
        "            \"\"\"\r\n",
        "st.markdown(hide_streamlit_style, unsafe_allow_html=True) \r\n",
        "def main():\r\n",
        "    premade = True\r\n",
        "    def make_df2():\r\n",
        "        test = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\r\n",
        "        test.rename(columns={'iso_code':'country_code_3', 'location':'country', 'date':'date_parsed', 'total_cases':'cases', 'total_deaths':'deaths'}, inplace=True)\r\n",
        "        test = test[test.country != 'World']\r\n",
        "        test.sort_values(by='date_parsed', inplace=True)\r\n",
        "        #test = pd.melt(test, id_vars=['country_code_3', 'country', 'date_parsed'], value_vars=['total_cases', 'total_deaths', 'total_cases_per_million', 'total_deaths_per_million'], var_name='category', value_name='cases')\r\n",
        "        return test\r\n",
        "    \r\n",
        "    def make_df_pop():\r\n",
        "        df_pop = pd.read_csv('https://raw.githubusercontent.com/datasets/population/master/data/population.csv')\r\n",
        "        df_pop = df_pop[df_pop.Year == df_pop.Year.max()]\r\n",
        "        df_pop = df_pop.rename(columns={'Country Name':'country', 'Country Code':'country_code_3', 'Value':'Population'}).drop(columns='Year')\r\n",
        "        return df_pop\r\n",
        "        \r\n",
        "    def make_df():\r\n",
        "        url_start = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_'\r\n",
        "        df = None\r\n",
        "        for category in ['confirmed', 'deaths', 'recovered']:\r\n",
        "            dd = pd.read_csv(url_start + category + '_global.csv')\r\n",
        "            dd['category'] = category\r\n",
        "            df = pd.concat([df, dd]) if df is not None else dd\r\n",
        "            \r\n",
        "        df = df[['category']+df.columns.values[:-1].tolist()]\r\n",
        "        df = pd.melt(df,id_vars=['category','Province/State', 'Country/Region', 'Lat', 'Long'],\r\n",
        "                                value_vars=df.columns.values[5:],\r\n",
        "                                var_name='date',value_name='cases')\r\n",
        "        \r\n",
        "        latlong = list(df[['Lat', 'Long']].itertuples(index=False, name=None))\r\n",
        "        \r\n",
        "        countrylist = rvg.search(latlong)\r\n",
        "        \r\n",
        "        df['country_code_2'] = [x['cc'] for x in countrylist]\r\n",
        "        df['country_code_3'] = df['country_code_2']\r\n",
        "        \r\n",
        "        convert_country_codes = {'AF':'AFG','AX':'ALA','AL':'ALB','DZ':'DZA','AS':'ASM','AD':'AND','AO':'AGO','AI':'AIA','AQ':'ATA','AG':'ATG','AR':'ARG','AM':'ARM',\r\n",
        "                                'AW':'ABW','AU':'AUS','AT':'AUT','AZ':'AZE','BS':'BHS','BH':'BHR','BD':'BGD','BB':'BRB','BY':'BLR','BE':'BEL','BZ':'BLZ','BJ':'BEN',\r\n",
        "                                'BM':'BMU','BT':'BTN','BO':'BOL','BA':'BIH','BW':'BWA','BV':'BVT','BR':'BRA','IO':'IOT','BN':'BRN','BG':'BGR','BF':'BFA','BI':'BDI',\r\n",
        "                                'KH':'KHM','CM':'CMR','CA':'CAN','CV':'CPV','KY':'CYM','CF':'CAF','TD':'TCD','CL':'CHL','CN':'CHN','CX':'CXR','CC':'CCK','CO':'COL',\r\n",
        "                                'KM':'COM','CG':'COG','CD':'COD','CK':'COK','CR':'CRI','CI':'CIV','HR':'HRV','CU':'CUB','CY':'CYP','CZ':'CZE','DK':'DNK','DJ':'DJI',\r\n",
        "                                'DM':'DMA','DO':'DOM','EC':'ECU','EG':'EGY','SV':'SLV','GQ':'GNQ','ER':'ERI','EE':'EST','ET':'ETH','FK':'FLK','FO':'FRO','FJ':'FJI',\r\n",
        "                                'FI':'FIN','FR':'FRA','GF':'GUF','PF':'PYF','TF':'ATF','GA':'GAB','GM':'GMB','GE':'GEO','DE':'DEU','GH':'GHA','GI':'GIB','GR':'GRC',\r\n",
        "                                'GL':'GRL','GD':'GRD','GP':'GLP','GU':'GUM','GT':'GTM','GG':'GGY','GN':'GIN','GW':'GNB','GY':'GUY','HT':'HTI','HM':'HMD','VA':'VAT',\r\n",
        "                                'HN':'HND','HK':'HKG','HU':'HUN','IS':'ISL','IN':'IND','ID':'IDN','IR':'IRN','IQ':'IRQ','IE':'IRL','IM':'IMN','IL':'ISR','IT':'ITA',\r\n",
        "                                'JM':'JAM','JP':'JPN','JE':'JEY','JO':'JOR','KZ':'KAZ','KE':'KEN','KI':'KIR','KP':'PRK','KR':'KOR','KW':'KWT','KG':'KGZ','LA':'LAO',\r\n",
        "                                'LV':'LVA','LB':'LBN','LS':'LSO','LR':'LBR','LY':'LBY','LI':'LIE','LT':'LTU','LU':'LUX','MO':'MAC','MK':'MKD','MG':'MDG','MW':'MWI',\r\n",
        "                                'MY':'MYS','MV':'MDV','ML':'MLI','MT':'MLT','MH':'MHL','MQ':'MTQ','MR':'MRT','MU':'MUS','YT':'MYT','MX':'MEX','FM':'FSM','MD':'MDA',\r\n",
        "                                'MC':'MCO','MN':'MNG','ME':'MNE','MS':'MSR','MA':'MAR','MZ':'MOZ','MM':'MMR','NA':'NAM','NR':'NRU','NP':'NPL','NL':'NLD','AN':'ANT',\r\n",
        "                                'NC':'NCL','NZ':'NZL','NI':'NIC','NE':'NER','NG':'NGA','NU':'NIU','NF':'NFK','MP':'MNP','NO':'NOR','OM':'OMN','PK':'PAK','PW':'PLW',\r\n",
        "                                'PS':'PSE','PA':'PAN','PG':'PNG','PY':'PRY','PE':'PER','PH':'PHL','PN':'PCN','PL':'POL','PT':'PRT','PR':'PRI','QA':'QAT','RE':'REU',\r\n",
        "                                'RO':'ROU','RU':'RUS','RW':'RWA','BL':'BLM','SH':'SHN','KN':'KNA','LC':'LCA','MF':'MAF','PM':'SPM','VC':'VCT','WS':'WSM','SM':'SMR',\r\n",
        "                                'ST':'STP','SA':'SAU','SN':'SEN','RS':'SRB','SC':'SYC','SL':'SLE','SG':'SGP','SK':'SVK','SI':'SVN','SB':'SLB','SO':'SOM','ZA':'ZAF',\r\n",
        "                                'GS':'SGS','ES':'ESP','LK':'LKA','SD':'SDN','SR':'SUR','SJ':'SJM','SZ':'SWZ','SE':'SWE','CH':'CHE','SY':'SYR','TW':'TWN','TJ':'TJK',\r\n",
        "                                'TZ':'TZA','TH':'THA','TL':'TLS','TG':'TGO','TK':'TKL','TO':'TON','TT':'TTO','TN':'TUN','TR':'TUR','TM':'TKM','TC':'TCA','TV':'TUV',\r\n",
        "                                'UG':'UGA','UA':'UKR','AE':'ARE','GB':'GBR','US':'USA','UM':'UMI','UY':'URY','UZ':'UZB','VU':'VUT','VE':'VEN','VN':'VNM','VG':'VGB',\r\n",
        "                                'VI':'VIR','WF':'WLF','EH':'ESH','YE':'YEM','ZM':'ZMB','ZW':'ZWE'}\r\n",
        "        \r\n",
        "        df.replace({\"country_code_3\":convert_country_codes},inplace=True)\r\n",
        "        df['date_parsed'] = pd.to_datetime(df['date'], format='%m/%d/%y')\r\n",
        "        \r\n",
        "        # Add world population\r\n",
        "        #df_pop = get_dataset(\"world_pop_2018\")[['Country Name', 'Country Code', '2018']]\r\n",
        "        #df_pop.rename(columns={'Country Name':'country', 'Country Code':'country_code_3', '2018':'Population'}, inplace=True)\r\n",
        "        df = df.merge(make_df_pop(), left_on='country_code_3', right_on='country_code_3')\r\n",
        "        \r\n",
        "        # Normalize by world population\r\n",
        "        df['cases_pop'] = 1000000*df['cases']/df['Population']\r\n",
        "        return df\r\n",
        "    \r\n",
        "    \r\n",
        "    def add_days_since_n(df, n):\r\n",
        "        out = None\r\n",
        "        for state in df['country'].unique():\r\n",
        "            #print(state)\r\n",
        "            co = df[df['country'] == state].copy()\r\n",
        "            italy_confirmed = co[co['category'] == 'confirmed'].copy()\r\n",
        "            tenormore = italy_confirmed['date_parsed'][italy_confirmed['cases']>n].copy()\r\n",
        "            if len(tenormore) > 0:\r\n",
        "                date_threshold = tenormore.values[0]\r\n",
        "                italy_confirmed.loc[:,'days_since_n'] = (1*(italy_confirmed['date_parsed'] >= date_threshold)).cumsum().values\r\n",
        "                italy_confirmed = italy_confirmed.loc[:,['date_parsed', 'days_since_n']].copy()\r\n",
        "                italy_confirmed.loc[:, 'country'] = state\r\n",
        "                out = italy_confirmed if out is None else pd.concat([out, italy_confirmed])\r\n",
        "        output = pd.merge(df, out, how='left')\r\n",
        "        return output\r\n",
        "    \r\n",
        "    def add_days_since_n(df, n):\r\n",
        "        out = None\r\n",
        "        for state in df['country'].unique():\r\n",
        "            #print(state)\r\n",
        "            co = df[df['country'] == state].copy()\r\n",
        "            italy_confirmed = co\r\n",
        "            tenormore = italy_confirmed['date_parsed'][italy_confirmed['cases']>n].copy()\r\n",
        "            if len(tenormore) > 0:\r\n",
        "                date_threshold = tenormore.values[0]\r\n",
        "                italy_confirmed.loc[:,'days_since_n'] = (1*(italy_confirmed['date_parsed'] >= date_threshold)).cumsum().values\r\n",
        "                italy_confirmed = italy_confirmed.loc[:,['date_parsed', 'days_since_n']].copy()\r\n",
        "                italy_confirmed.loc[:, 'country'] = state\r\n",
        "                out = italy_confirmed if out is None else pd.concat([out, italy_confirmed])\r\n",
        "        output = pd.merge(df, out, how='left')\r\n",
        "        return output\r\n",
        "    \r\n",
        "    def my_smoothie(df, x, window):\r\n",
        "        return df[x].rolling(window).mean().ewm(span=3).mean()\r\n",
        "    \r\n",
        "    def compute_new_cases(tdf, window):\r\n",
        "        for category in ['cases', 'deaths']:\r\n",
        "            tdf[category+'_smoothed'] = my_smoothie(tdf, category, window)\r\n",
        "            tdf[category+'_speed'] = tdf[category+''].groupby(['country']).diff()\r\n",
        "            tdf[category+'_speed_smoothed'] = my_smoothie(tdf,category+'_speed', window)\r\n",
        "            tdf[category+'_acceleration'] = tdf[category+'_speed_smoothed'].diff()\r\n",
        "            tdf[category+'_acceleration_smoothed'] = my_smoothie(tdf,category+'_acceleration', window)\r\n",
        "        return tdf\r\n",
        "    \r\n",
        "    def compute_new_cases_pop(tdf, window):\r\n",
        "        for category in ['cases', 'deaths']:\r\n",
        "            tdf[category+'_per_million_smoothed'] = my_smoothie(tdf, category+'_per_million', window)\r\n",
        "            tdf[category+'_per_million_speed'] = tdf[category+'_per_million'].groupby(['country']).diff()\r\n",
        "            tdf[category+'_per_million_speed_smoothed'] = my_smoothie(tdf,category+'_per_million_speed', window)\r\n",
        "            tdf[category+'_per_million_acceleration'] = tdf[category+'_per_million_speed_smoothed'].diff()\r\n",
        "            tdf[category+'_per_million_acceleration_smoothed'] = my_smoothie(tdf,category+'_per_million_acceleration', window)\r\n",
        "        return tdf\r\n",
        "    \r\n",
        "    def myplot(df, x, y, countries, category, scatter=False):\r\n",
        "        fig, ax = plt.subplots(figsize=(15,12))\r\n",
        "        for country, cdf in df[df.days_since_n > 0].loc[(countries, category),:].groupby('country'):\r\n",
        "            if scatter:\r\n",
        "                cdf.plot(kind='scatter',x='days_since_n',y=y, ax=ax, label=country)\r\n",
        "            cdf.plot(kind='line',x=x,y=y, ax=ax, label=country, linewidth=3)\r\n",
        "        ax.axhline(y=0, color='black')\r\n",
        "        grid(b=True, which='major', color='lightgray', linestyle='-', axis='y')\r\n",
        "        ax.tick_params(axis='both', labelsize=16)\r\n",
        "        plt.show()\r\n",
        "    \r\n",
        "    def myplotly(df, x, y, countries, category, scatter = False):\r\n",
        "        fig = px.line(df[df.days_since_n > 0].loc[countries,:].reset_index(), x=x, y=y, title=\"\", color='country', template='plotly_white').for_each_trace(lambda t: t.update(name=t.name.split(\"=\")[1]))\r\n",
        "        fig.update_layout(xaxis_title=\"\", yaxis_title=\"\", height=500,\r\n",
        "        #legend=dict(yanchor=\"top\",y=0.99,xanchor=\"left\",x=0.01)\r\n",
        "        legend={\"orientation\":'h'}\r\n",
        "        )\r\n",
        "\r\n",
        "        return fig\r\n",
        "\r\n",
        "    def make_map(df, variable):\r\n",
        "      yesterday = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\r\n",
        "      #chosen_date = df.date_parsed.max()\r\n",
        "      chosen_date = yesterday\r\n",
        "      current = df[df.date_parsed==chosen_date].reset_index()\r\n",
        "      current = current[current['population'] > 10**6]\r\n",
        "      fig = px.choropleth(current, locations=\"country_code_3\",\r\n",
        "                    color=variable,\r\n",
        "                    hover_name=\"country\",\r\n",
        "                    color_continuous_scale=px.colors.diverging.Spectral_r\r\n",
        "                    )\r\n",
        "      fig.update_layout(height=500,coloraxis_colorbar=dict(title=\"\"))\r\n",
        "      return fig\r\n",
        "\r\n",
        "    def plot_date(df, y , countries, category, scatter=False, smooth=False):\r\n",
        "        fig, ax = plt.subplots(figsize=(10,10))\r\n",
        "        smooth = '_smoothed' if smooth else ''\r\n",
        "        for country, cdf in df[df.days_since_n > 0].loc[(countries, category),:].groupby('country'):\r\n",
        "            if scatter:\r\n",
        "                cdf.plot(kind='scatter',x='days_since_n',y=y, ax=ax, label=country)\r\n",
        "            cdf.plot(kind='line',x='date_parsed',y=y+smooth, ax=ax, label=country, linewidth=3)\r\n",
        "        ax.axhline(y=0, color='black')\r\n",
        "        grid(b=True, which='major', color='lightgray', linestyle='-', axis='y')\r\n",
        "        ax.tick_params(axis='both', labelsize=16)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    def make_france():\r\n",
        "        df = pd.read_csv('https://raw.githubusercontent.com/opencovid19-fr/data/master/dist/chiffres-cles.csv')\r\n",
        "        dep = df[df.granularite == \"departement\"]\r\n",
        "        dep['maille_code'] = dep.maille_code.str.split(\"-\",expand=True).loc[:,1]\r\n",
        "        dep.rename(columns={'maille_code':'dep_id'}, inplace=True)\r\n",
        "\r\n",
        "        dep_pop = pd.DataFrame(pd.read_html(\"https://en.wikipedia.org/wiki/List_of_French_departments_by_population\")[0])[[\"Legal population in 2013\", \"INSEE Dept. No.\"]]\r\n",
        "        dep_pop.rename(columns={\"Legal population in 2013\":\"population\", \"INSEE Dept. No.\":\"dep_id\"}, inplace=True)\r\n",
        "        dep_pop\r\n",
        "\r\n",
        "        return pd.merge(dep,dep_pop)\r\n",
        "\r\n",
        "    def get_indices(olist, clist):\r\n",
        "        default_ix = []\r\n",
        "        for it in clist:\r\n",
        "            default_ix.append(olist.index(it))\r\n",
        "        return default_ix\r\n",
        "\r\n",
        "    @st.cache(persist=True)\r\n",
        "    def build_df():\r\n",
        "        df = make_df2() if premade else make_df()\r\n",
        "        output = add_days_since_n(df, n=100)\r\n",
        "        df = output.set_index(['country', 'date_parsed']).copy()\r\n",
        "        df.rename(columns={'total_deaths_per_million':'deaths_per_million', 'total_cases_per_million':'cases_per_million'}, inplace=True)\r\n",
        "        df.sort_values(by=['country', 'date_parsed'],inplace=True)\r\n",
        "        df = compute_new_cases(df, window=7)\r\n",
        "        df = compute_new_cases_pop(df, window=7)\r\n",
        "        df.reset_index('date_parsed', drop=False, inplace=True)\r\n",
        "        return df\r\n",
        "\r\n",
        "    df = build_df()\r\n",
        "\r\n",
        "\r\n",
        "    st.title(\"Covid-19 Dashboard\")\r\n",
        "    #st.subheader(\"How to run streamlit from colab\")\r\n",
        "    countries = list(np.unique(df.index.values))\r\n",
        "    if df.date_parsed.max() != datetime.now().strftime('%Y-%m-%d'):\r\n",
        "      ask_refresh = st.sidebar.button(\"Refresh data\")\r\n",
        "    choice_countries = st.sidebar.multiselect('Choose countries:', countries, \r\n",
        "                                              default = ['France', 'Spain', \"United Kingdom\"])\r\n",
        "    choice_category = st.sidebar.radio(\"Category:\",('Cases', 'Deaths'), index = 0)\r\n",
        "    category = str.lower(choice_category)\r\n",
        "    choice_variable = st.sidebar.radio(\"Evolution:\",('Cumulative', 'Daily'), index = 1)\r\n",
        "    variable = \"_speed\" if choice_variable == \"Daily\" else \"\"\r\n",
        "    \r\n",
        "    choice_perm = st.sidebar.radio(\"Normalize by population:\",('Yes', 'No'), index = 0)\r\n",
        "    perm = \"_per_million\" if choice_perm == \"Yes\" else \"\"\r\n",
        "    text_perm = ' per million inhabitants' if choice_perm == \"Yes\" else \"\"\r\n",
        "    choice_smoothed = st.sidebar.radio(\"Weekly rolling average\",('Yes', 'No'), index = 0)\r\n",
        "    smoothed = \"_smoothed\" if choice_smoothed == \"Yes\" else \"\"\r\n",
        "    text_smoothed = ', weekly rolling average' if choice_smoothed == \"Yes\" else \"\"\r\n",
        "    y = category+perm+variable+smoothed\r\n",
        "\r\n",
        "    if ask_refresh:\r\n",
        "      if df.date_parsed.max() != datetime.now().strftime('%Y-%m-%d'):\r\n",
        "        df = build_df()\r\n",
        "    st.subheader(f'{choice_variable} {category}{text_perm}{text_smoothed}')\r\n",
        "    #st.write(myplotly(df, 'date_parsed', y, choice_countries, \"cases\"))\r\n",
        "    st.plotly_chart(myplotly(df, 'date_parsed', y, choice_countries, \"cases\"))\r\n",
        "    st.text(f'Latest {str.lower(choice_variable)} {category}{text_perm}{text_smoothed}:')\r\n",
        "    st.write(make_map(df, y))\r\n",
        "if __name__ == '__main__':\r\n",
        "    main()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting covid.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geOc_so5DQ2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df48b553-c5ac-47b5-b437-436e599719e1"
      },
      "source": [
        "!streamlit run covid.py &>/dev/null&\r\n",
        "!pgrep streamlit\r\n",
        "ngrok.kill()\r\n",
        "public_url = ngrok.connect(port='8501')\r\n",
        "print(public_url)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123\n",
            "166\n",
            "213\n",
            "295\n",
            "330\n",
            "http://17d258a4a761.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McqtC_kfbrXr"
      },
      "source": [
        "https://blog.octo.com/creer-une-web-app-interactive-en-10min-avec-streamlit/"
      ]
    }
  ]
}